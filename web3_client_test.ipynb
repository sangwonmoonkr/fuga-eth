{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sangwon\\anaconda3\\envs\\fuga\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, Dict, Tuple\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import web3\n",
    "from logging import INFO\n",
    "\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv()\n",
    "# abi = json.load(open('contract/build/contracts/FugaController.json', 'r'))['abi']\n",
    "# S3_ACCESS_KEY = os.environ.get('S3_ACCESS_KEY')\n",
    "# S3_SCRETE_KEY = os.environ.get('S3_SCRETE_KEY')\n",
    "# BUCKET_NAME = 'fugaeth'\n",
    "# HTTP_PROVIDER = os.environ.get('HTTP_PROVIDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def listen_for_event(contract, event_name):\n",
    "    # create a filter to listen for the specified event\n",
    "    event_filter = contract.events[event_name].createFilter(fromBlock='latest')\n",
    "\n",
    "    while True:\n",
    "        # check if any new events have been emitted\n",
    "        for event in event_filter.get_new_entries():\n",
    "            # if the specified event has been emitted, return its message\n",
    "            if event.event == event_name:\n",
    "                yield event.args\n",
    "        # wait for new events\n",
    "        time.sleep(5)\n",
    "\n",
    "def web3_connection(s3, w3, contract) -> Tuple[Callable[[], Dict], Callable[[Dict], None]]:\n",
    "    \"\"\"\n",
    "    Creates a connection to the blockchain and returns a function to receive messages and a function to send messages.\n",
    "    \"\"\"\n",
    "    web3_message_iterator = listen_for_event(contract, \"ServerMessage\")\n",
    "\n",
    "    def receive():\n",
    "        try:\n",
    "            return next(web3_message_iterator)\n",
    "        except StopIteration:\n",
    "            return None\n",
    "\n",
    "    def send(msg):\n",
    "        return handle_send(msg, s3, w3, contract)\n",
    "\n",
    "    return (receive, send)\n",
    "\n",
    "# def listen_for_event(contract, event_name):\n",
    "#     # create a filter to listen for the specified event\n",
    "#     event_filter = contract.events[event_name].createFilter(fromBlock='latest')\n",
    "\n",
    "#     while True:\n",
    "#         # check if any new events have been emitted\n",
    "#         for event in event_filter.get_new_entries():\n",
    "#             # if the specified event has been emitted, return its message\n",
    "#             if event.event == event_name:\n",
    "#                 yield event.args\n",
    "#                 return\n",
    "#         # wait for new events\n",
    "# #         time.sleep(5)\n",
    "\n",
    "# def web3_connection(s3, w3, contract) -> Tuple[Callable[[], Dict], Callable[[Dict], None]]:\n",
    "#     \"\"\"\n",
    "#     Creates a connection to the blockchain and returns a function to receive messages and a function to send messages.    \n",
    "#     \"\"\"\n",
    "#     # create a filter to listen for the specified event\n",
    "#     web3_message_iterator = listen_for_event(contract, \"ServerMessage\")\n",
    "\n",
    "#     # create a function that returns the next message\n",
    "#     def receive():\n",
    "#         try:\n",
    "#             return next(web3_message_iterator)\n",
    "#         except StopIteration:\n",
    "#             return None\n",
    "#     def send(msg):\n",
    "#         return handle_send(msg, s3, w3, contract)\n",
    "#     # receive: Callable[[], Dict] = lambda: next(web3_message_iterator)\n",
    "#     # send: Callable[[Dict], None] = lambda msg: handle_send(msg, s3, w3, contract)\n",
    "\n",
    "#     return (receive, send)\n",
    "\n",
    "\n",
    "def handle_receive(client, msg, s3, w3, contract):\n",
    "    \"\"\"\n",
    "    Handles a received message.\n",
    "    Returns a tuple containing the response message, the number of samples and a boolean indicating whether the client should shut down.\n",
    "    \"\"\"\n",
    "    # check the field of the message\n",
    "    field = msg['field']\n",
    "\n",
    "    if field == \"Finished\":\n",
    "        print(\"finished\")\n",
    "        return None, 0, False\n",
    "\n",
    "    # if the message is a request for Ready, join the round\n",
    "    if field == \"Ready\":\n",
    "        print(\"join round\")\n",
    "        function = getattr(contract.functions, 'joinRound')()\n",
    "\n",
    "    # if the message is a request for JoinRound, after few minutes, start the round\n",
    "    if field == \"JoinRound\":\n",
    "        time.sleep(1*20)\n",
    "        print(\"call start round\")\n",
    "        function = getattr(contract.functions, 'startRound')()\n",
    "\n",
    "    if field == \"Ready\" or field == \"JoinRound\":\n",
    "        send_transaction(w3, contract, function)\n",
    "        return None, 0, True\n",
    "\n",
    "    # if the message is a request for the ConfigIns, set the Config data\n",
    "    if field == \"ConfigIns\":\n",
    "        print(\"config start\")\n",
    "        # receive the Config data\n",
    "        # function = getattr(contract.functions, 'getConfig')()\n",
    "        # response = contract.functions.getConfig().call()\n",
    "        response = read_transaction(w3, contract, 'getConfig')\n",
    "        \n",
    "        print(response)\n",
    "        \n",
    "        self_centered = response['self_centered']\n",
    "        batch_size = response['batch_size']\n",
    "        learning_rate = float(response['learning_rate'])\n",
    "        local_epochs = response['local_epochs']\n",
    "        val_steps = response['val_steps']\n",
    "\n",
    "        config = {'self_centered': self_centered, 'batch_size': batch_size, 'lr' : learning_rate ,'local_epochs': local_epochs, 'val_steps': val_steps}\n",
    "\n",
    "        client.set_config(config)\n",
    "\n",
    "        return {'field':'ConfigRes'}, 0, True\n",
    "        \n",
    "    # if the message is a request for the FitIns, aggregate the model and return the result after fit\n",
    "    if field == \"FitIns\":\n",
    "        print(\"fit start\")\n",
    "        # receive the Client data\n",
    "        # response = contract.functions.getClient().call()\n",
    "        response = read_transaction(w3, contract, 'getClient')\n",
    "        print(response)\n",
    "\n",
    "        self_model_hash = response['model_hash']\n",
    "        self_num_sample = response['num_sample']\n",
    "        self_score = response['score']\n",
    "\n",
    "        model_hashes = []\n",
    "        num_samples = []\n",
    "        scores = []\n",
    "\n",
    "        # if(make_hash(client.get_parameters()) != self_model_hash):\n",
    "        #     print(\"model hash is not matched, Retreive model from blockchain\")\n",
    "        #     object_key = f'models/{self_model_hash}.bin'\n",
    "        #     file_path = object_key\n",
    "        #     s3.download_file(BUCKET_NAME, object_key, file_path)\n",
    "        #     # check hash value\n",
    "        #     if(not check_model(self_model_hash)):\n",
    "        #         client.init_model()\n",
    "        # client.fit(client.get_parameters())\n",
    "\n",
    "        # receive the FitIns data\n",
    "        # response = contract.functions.FitIns().call()\n",
    "        response = read_transaction(w3, contract, 'FitIns')\n",
    "        print(response)\n",
    "        \n",
    "        other_model_hashes = response['model_hashes']\n",
    "        other_num_samples =response['num_samples']\n",
    "        other_scores = response['scores']\n",
    "\n",
    "        for model_hash in other_model_hashes:\n",
    "            object_key = f'models/{model_hash}.bin'\n",
    "            file_path = object_key\n",
    "            s3.download_file(BUCKET_NAME, object_key, file_path)\n",
    "\n",
    "            # check hash value\n",
    "            if(check_model(model_hash)):\n",
    "                model_hashes.append(model_hash)\n",
    "                num_samples.append(other_num_samples)\n",
    "                scores.append(other_scores)\n",
    "\n",
    "        if(check_model(self_model_hash)):\n",
    "            model_hashes.append(self_model_hash)\n",
    "            num_samples.append(self_num_sample)\n",
    "            scores.append(sum(scores) if client.self_centered else self_score)\n",
    "            if(len(scores)==1, scores[0]==0):\n",
    "                scores[0] = 1\n",
    "\n",
    "        # aggregate the model\n",
    "        fitres = aggregate_fit(client, model_hashes, num_samples, scores)\n",
    "\n",
    "        # return the result of fit\n",
    "        return {'field':'FitRes', 'data': fitres},0, True\n",
    "    \n",
    "    # if the message is a request for the EvaluateIns, evaluate the model and return the result\n",
    "    elif field == \"EvaluateIns\":\n",
    "        print(\"eval start\")\n",
    "        # evaluate the model on client\n",
    "        # response = contract.functions.EvaluateIns().call()\n",
    "        response = read_transaction(w3, contract, 'EvaluateIns')\n",
    "        print(response)\n",
    "\n",
    "        model_hashes = response['model_hashes']\n",
    "        evalres = {}\n",
    "\n",
    "        for model_hash in model_hashes:\n",
    "            object_key = f'models/{model_hash}.bin'\n",
    "            file_path = object_key\n",
    "\n",
    "            s3.download_file(BUCKET_NAME, object_key, file_path)\n",
    "\n",
    "            # check hash value\n",
    "            check_model(model_hash)\n",
    "            param = read_model(model_hash)\n",
    "\n",
    "            # evaluate the model\n",
    "            loss, _, _ = client.evaluate(param)\n",
    "            evalres[model_hash] = loss\n",
    "\n",
    "        return {'field':'EvaluateRes', 'data':evalres}, 0 , True\n",
    "\n",
    "\n",
    "def handle_send(msg, s3, w3, contract):\n",
    "    \"\"\"\n",
    "    Handles a message to be sent.\n",
    "    Returns the transaction receipt.\n",
    "    \"\"\"\n",
    "    # check the field of the message\n",
    "    field = msg['field']\n",
    "\n",
    "    # If the message is a ConfigRes, upload the result to the blockchain\n",
    "    if field == 'ConfigRes':\n",
    "        print(\"config complete\")\n",
    "        function = getattr(contract.functions, 'ConfigRes')()\n",
    "\n",
    "    # If the message is a FitRes, save model and upload model hash to the blockchain\n",
    "    if field == 'FitRes':\n",
    "        print(\"fit complete\")\n",
    "        # get the message params\n",
    "        parameters_prime, num_examples_train, results = msg['data']\n",
    "\n",
    "        # hash the message params which is dictionary\n",
    "        model_hash = make_hash(parameters_prime)\n",
    "\n",
    "        # save and upload the model\n",
    "        upload_model(s3, parameters_prime)\n",
    "\n",
    "        # prepare the arguments for the FitRes function\n",
    "        args = [model_hash, num_examples_train]\n",
    "\n",
    "        # get the function object from the contract ABI\n",
    "        function = getattr(contract.functions, 'FitRes')(*args)\n",
    "\n",
    "    # If the message is a EvaluateRes, upload the result to the blockchain\n",
    "    elif field == 'EvaluateRes':\n",
    "        print(\"eval complete\")\n",
    "        # get the message params\n",
    "        evalres = msg['data']\n",
    "        model_hashes = list(evalres.keys())\n",
    "        values = list(evalres.values())\n",
    "        args = [model_hashes, values]\n",
    "\n",
    "        # get the function object from the contract ABI\n",
    "        function = getattr(contract.functions, 'EvaluateRes')(*args)\n",
    "\n",
    "    send_transaction(w3, contract, function)\n",
    "\n",
    "\n",
    "\n",
    "def start_web3_client(client, contract_address, abi):\n",
    "\n",
    "    while True:\n",
    "        s3 = s3_connection()\n",
    "        w3 = web3.Web3(web3.HTTPProvider(HTTP_PROVIDER))\n",
    "        contract = w3.eth.contract(address=contract_address, abi=abi)\n",
    "        receive,send = web3_connection(s3, w3, contract)\n",
    "        # receive,send = next(conn)\n",
    "\n",
    "        while True:\n",
    "            server_message = receive()\n",
    "            print(\"server message : \",server_message)\n",
    "            if(server_message is not None):\n",
    "                client_message, sleep_duration, keep_going = handle_receive(\n",
    "                    client, server_message, s3, w3, contract\n",
    "                )\n",
    "                if(client_message is not None):\n",
    "                    send(client_message)\n",
    "        \n",
    "                if not keep_going:\n",
    "                    break\n",
    "\n",
    "        # Check if we should disconnect and shut down\n",
    "        if sleep_duration == 0:\n",
    "            print(\"Disconnect and shut down\")\n",
    "            break\n",
    "        # Sleep and reconnect afterwards\n",
    "        print(\"Sleeping for {} seconds\".format(sleep_duration))\n",
    "        time.sleep(sleep_duration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import flwr as fl\n",
    "import torch\n",
    "from datasets import load_dataset, load_metric\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load IMDB data (training and eval)\"\"\"\n",
    "    raw_datasets = load_dataset(\"imdb\")\n",
    "    raw_datasets = raw_datasets.shuffle(seed=42)\n",
    "\n",
    "    # remove unnecessary data split\n",
    "    del raw_datasets[\"unsupervised\"]\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "\n",
    "    # random 10 samples\n",
    "    population = random.sample(range(len(raw_datasets[\"train\"])), 10)\n",
    "\n",
    "    tokenized_datasets = raw_datasets.map(\n",
    "        lambda examples: tokenizer(examples[\"text\"], truncation=True), batched=True\n",
    "    )\n",
    "    tokenized_datasets[\"train\"] = tokenized_datasets[\"train\"].select(population)\n",
    "    tokenized_datasets[\"test\"] = tokenized_datasets[\"test\"].select(population)\n",
    "\n",
    "    tokenized_datasets = tokenized_datasets.remove_columns(\"text\")\n",
    "    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    trainloader = DataLoader(\n",
    "        tokenized_datasets[\"train\"],\n",
    "        shuffle=True,\n",
    "        batch_size=32,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "\n",
    "    testloader = DataLoader(\n",
    "        tokenized_datasets[\"test\"], batch_size=32, collate_fn=data_collator\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(net, trainloader, epochs ,learning_rate):\n",
    "    optimizer = AdamW(net.parameters(), lr=learning_rate)\n",
    "    net.train()\n",
    "    for _ in range(epochs):\n",
    "        for batch in trainloader:\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            outputs = net(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    metric = load_metric(\"accuracy\")\n",
    "    loss = 0\n",
    "    net.eval()\n",
    "    for batch in testloader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = net(**batch)\n",
    "        logits = outputs.logits\n",
    "        loss += outputs.loss.item()\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = metric.compute()[\"accuracy\"]\n",
    "    return loss, accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBClient(fl.client.NumPyClient):\n",
    "    def __init__(self) -> None:\n",
    "        self.net = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"albert-base-v2\", num_labels=2\n",
    "        ).to(DEVICE)\n",
    "        self.trainloader, self.testloader = load_data()\n",
    "        self.config = None\n",
    "    \n",
    "    def init_model(self):\n",
    "        self.net = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"albert-base-v2\", num_labels=2\n",
    "        ).to(DEVICE)\n",
    "\n",
    "    def set_config(self, config) :\n",
    "        self.config = config\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.net.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        self.net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters):\n",
    "        self.set_parameters(parameters)\n",
    "        print(\"Training Started...\")\n",
    "        train(self.net, self.trainloader, epochs=self.config[\"local_epochs\"], learning_rate=self.config[\"learning_rate\"])\n",
    "        print(\"Training Finished.\")\n",
    "        print(\"Test Results : \", test(self.net, self.testloader))\n",
    "        return self.get_parameters(), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters):\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = test(self.net, self.testloader)\n",
    "        return float(loss), len(self.testloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.decoder.bias', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.decoder.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Found cached dataset imdb (C:/Users/sangwon/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 157.78it/s]\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\sangwon\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-28baff4d72a1efe2.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\sangwon\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-85094476e34a4173.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\sangwon\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-31731e9a6744a7b4.arrow\n",
      "Loading cached processed dataset at C:\\Users\\sangwon\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-21570886a3fb19af.arrow\n",
      "Loading cached processed dataset at C:\\Users\\sangwon\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-1c4cb72287115465.arrow\n"
     ]
    }
   ],
   "source": [
    "client = IMDBClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 bucket connected!\n",
      "server message :  AttributeDict({'field': 'JoinRound'})\n",
      "call start round\n",
      "server message :  AttributeDict({'field': 'ConfigIns'})\n",
      "config start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sangwon\\anaconda3\\envs\\fuga\\lib\\site-packages\\web3\\contract.py:1198: UserWarning: The log with transaction hash: HexBytes('0x98e8e7f91dd8c83b6db504f7bc117e9d54e8cfd8afe7619bab62b9f77f9bcd13') and logIndex: 3 encountered the following error during processing: MismatchedABI(The event signature did not match the provided ABI). It has been discarded.\n",
      "  f\"The log with transaction hash: {log['transactionHash']!r} and \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeDict({'self_centered': True, 'batch_size': 1, 'learning_rate': '0.00005', 'local_epochs': 1, 'val_steps': 5})\n",
      "config complete\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32308\\3408305217.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstart_web3_client\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'0xbB8977D0604ABe3FA3d368e15D96426Ed91a06C0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32308\\3396495834.py\u001b[0m in \u001b[0;36mstart_web3_client\u001b[1;34m(client, contract_address, abi)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[0mserver_message\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreceive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"server message : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mserver_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserver_message\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32308\\3396495834.py\u001b[0m in \u001b[0;36mreceive\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreceive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweb3_message_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32308\\3396495834.py\u001b[0m in \u001b[0;36mlisten_for_event\u001b[1;34m(contract, event_name)\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# wait for new events\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mweb3_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontract\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_web3_client(client, '0xbB8977D0604ABe3FA3d368e15D96426Ed91a06C0', abi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFURA_API_KEY = os.environ.get('INFURA_API_KEY')\n",
    "MNEMONIC = os.environ.get('MNEMONIC')\n",
    "abi = json.load(open('contract/build/contracts/Test.json', 'r'))['abi']\n",
    "w3 = web3.Web3()\n",
    "w3.eth.account.enable_unaudited_hdwallet_features()\n",
    "account = w3.eth.account.from_mnemonic(MNEMONIC, account_path=\"m/44'/60'/0'/0/0\")\n",
    "w3 = web3.Web3(web3.HTTPProvider(f'https://sepolia.infura.io/v3/{INFURA_API_KEY}'))\n",
    "contract = w3.eth.contract(address='0x8309F6a4BBb56caEC4c197Efd00287e748017162', abi=abi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttributeDict({'blockHash': HexBytes('0xc7fab322a8e6b67850bebec4fa7a406bc1df1827582458463f539ff3e0f5f7e5'),\n",
       " 'blockNumber': 3295748,\n",
       " 'contractAddress': None,\n",
       " 'cumulativeGasUsed': 1024850,\n",
       " 'effectiveGasPrice': 1000000008,\n",
       " 'from': '0x08cA4DCa530A7c02d7755455AeB24B63A41C8608',\n",
       " 'gasUsed': 23802,\n",
       " 'logs': [],\n",
       " 'logsBloom': HexBytes('0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000'),\n",
       " 'status': 1,\n",
       " 'to': '0x8309F6a4BBb56caEC4c197Efd00287e748017162',\n",
       " 'transactionHash': HexBytes('0x99c487885d648391a653ced4ecf2d21157c40349967e20940c59a954671b5ee9'),\n",
       " 'transactionIndex': 15,\n",
       " 'type': '0x2'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = [1]\n",
    "function = getattr(contract.functions, 'setScore')(*args)\n",
    "\n",
    "# Create a transaction for calling the function\n",
    "transaction = function.buildTransaction()\n",
    "\n",
    "# Estimate the gas required for the transaction\n",
    "gas_estimate = w3.eth.estimateGas(transaction)\n",
    "\n",
    "# Set up the transaction parameters\n",
    "transaction.update({\n",
    "    'from': account.address,\n",
    "    'to': contract.address,\n",
    "    'gas': gas_estimate,\n",
    "    'nonce': w3.eth.getTransactionCount(account.address),\n",
    "})\n",
    "\n",
    "# Sign the transaction\n",
    "signed_transaction = w3.eth.account.signTransaction(transaction, account.key)\n",
    "\n",
    "# Send the transaction\n",
    "transaction_hash = w3.eth.sendRawTransaction(signed_transaction.rawTransaction)\n",
    "\n",
    "# Wait for the transaction to be mined\n",
    "transaction_receipt = w3.eth.waitForTransactionReceipt(transaction_hash)\n",
    "\n",
    "transaction_receipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contract.functions.setScore(2).call()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
